{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature pyramid network experiments",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPV3oMy3CXzdSCkcBjD7xGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actionpackedgeneral/FPN/blob/main/feature_pyramid_network_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MQfRQ5eR2bn",
        "outputId": "b8653c2d-9555-4558-b82e-6eed29570613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting strawberry-graphql==0.96.0\n",
            "  Downloading strawberry_graphql-0.96.0-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiftyone) (57.4.0)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dacite>=1.6.0\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fiftyone) (3.2.2)\n",
            "Collecting fiftyone-db<0.4,>=0.3\n",
            "  Downloading fiftyone_db-0.3.0-py3-none-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.3-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.0 MB/s \n",
            "\u001b[?25hCollecting ndjson\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting pprintpp\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting sseclient-py<2,>=1.7.2\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.8.9)\n",
            "Collecting plotly<5,>=4.14\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from fiftyone) (2022.1)\n",
            "Collecting Jinja2>=3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 55.0 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 45 kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from fiftyone) (3.13)\n",
            "Collecting fiftyone-brain<0.9,>=0.8\n",
            "  Downloading fiftyone_brain-0.8.2-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (7.1.2)\n",
            "Collecting hypercorn>=0.13.2\n",
            "  Downloading Hypercorn-0.13.2-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting voxel51-eta<0.8,>=0.7.0\n",
            "  Downloading voxel51_eta-0.7.0-py2.py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting mongoengine==0.20.0\n",
            "  Downloading mongoengine-0.20.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fiftyone) (21.3)\n",
            "Collecting motor<3,>=2.3\n",
            "  Downloading motor-2.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting sse-starlette<1,>=0.10.3\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.18.3)\n",
            "Collecting argcomplete\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting starlette==0.16.0\n",
            "  Downloading starlette-0.16.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 258 kB/s \n",
            "\u001b[?25hCollecting retrying\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.21.6)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 133 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.3.5)\n",
            "Collecting pymongo<4,>=3.11\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting eventlet\n",
            "  Downloading eventlet-0.33.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.0.2)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-0.8.0-py3-none-any.whl (13 kB)\n",
            "Collecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from starlette==0.16.0->fiftyone) (4.2.0)\n",
            "Collecting python-multipart<0.0.6,>=0.0.5\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: click<9.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (7.1.2)\n",
            "Collecting graphql-core<3.2.0,>=3.1.0\n",
            "  Downloading graphql_core-3.1.7-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting backports.cached-property<2.0.0,>=1.0.1\n",
            "  Downloading backports.cached_property-1.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: pygments<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.96.0->fiftyone) (2.6.1)\n",
            "Collecting sentinel<0.4.0,>=0.3.0\n",
            "  Downloading sentinel-0.3.0-py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.16.0->fiftyone) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from fiftyone-brain<0.9,>=0.8->fiftyone) (1.4.1)\n",
            "Collecting wsproto>=0.14.0\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting h2>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting h11\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting priority\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly<5,>=4.14->fiftyone) (1.15.0)\n",
            "Collecting httpx>=0.10.0\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.5.18.1)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting h11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (4.11.4)\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (1.24.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (1.5.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (0.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.8,>=0.7.0->fiftyone) (0.3.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->voxel51-eta<0.8,>=0.7.0->fiftyone) (3.8.0)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.3\n",
            "  Downloading botocore-1.27.3-py3-none-any.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 39.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.7/dist-packages (from eventlet->fiftyone) (1.1.2)\n",
            "Collecting dnspython>=1.15.0\n",
            "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (1.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->voxel51-eta<0.8,>=0.7.0->fiftyone) (3.0.4)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.6.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Building wheels for collected packages: python-multipart, retrying\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=75286e426818ad08f39719b5d5910eb1139d0b20224704415b9aa165a24bf693\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=daacb6032e3dd594d35e8530a8b3c22076bb0dd16da6ee0c822721f390f29d23\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built python-multipart retrying\n",
            "Installing collected packages: sniffio, urllib3, rfc3986, jmespath, h11, anyio, hyperframe, httpcore, hpack, botocore, wsproto, toml, starlette, sentinel, s3transfer, retrying, python-multipart, pymongo, priority, patool, opencv-python-headless, ndjson, httpx, h2, graphql-core, dnspython, backports.cached-property, argcomplete, xmltodict, voxel51-eta, universal-analytics-python3, strawberry-graphql, sseclient-py, sse-starlette, pprintpp, plotly, motor, mongoengine, kaleido, Jinja2, hypercorn, fiftyone-db, fiftyone-brain, eventlet, Deprecated, dacite, boto3, aiofiles, fiftyone\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 Jinja2-3.1.2 aiofiles-0.8.0 anyio-3.6.1 argcomplete-2.0.0 backports.cached-property-1.0.1 boto3-1.24.3 botocore-1.27.3 dacite-1.6.0 dnspython-2.2.1 eventlet-0.33.1 fiftyone-0.16.2 fiftyone-brain-0.8.2 fiftyone-db-0.3.0 graphql-core-3.1.7 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.15.0 httpx-0.23.0 hypercorn-0.13.2 hyperframe-6.0.1 jmespath-1.0.0 kaleido-0.2.1 mongoengine-0.20.0 motor-2.5.1 ndjson-0.3.1 opencv-python-headless-4.5.5.64 patool-1.12 plotly-4.14.3 pprintpp-0.4.0 priority-2.0.0 pymongo-3.12.3 python-multipart-0.0.5 retrying-1.3.3 rfc3986-1.5.0 s3transfer-0.6.0 sentinel-0.3.0 sniffio-1.2.0 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.16.0 strawberry-graphql-0.96.0 toml-0.10.2 universal-analytics-python3-1.1.1 urllib3-1.25.11 voxel51-eta-0.7.0 wsproto-1.1.0 xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.5.18.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbBCsTGPTw2c",
        "outputId": "6a9434f9-239f-4c89-d331-43748d5da238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f68246ef4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.5.4.60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv_K2Cs4v6D3",
        "outputId": "dd719073-d92c-4c06-ab02-b29d29015ebb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.5.4.60\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.4.60) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.64\n",
            "    Uninstalling opencv-python-headless-4.5.5.64:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Successfully installed opencv-python-headless-4.5.4.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fo_dataset = foz.load_zoo_dataset(\"coco-2017\", \"validation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "5DcEET2GqGgR",
        "outputId": "9cdca7a3-3e3b-48ac-ccd5-21090ebfa2bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2472c5015005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfo_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_zoo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coco-2017\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'foz' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fo_dataset.compute_metadata()"
      ],
      "metadata": {
        "id": "m1-TXSynUchs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(fo_dataset)\n"
      ],
      "metadata": {
        "id": "8c1kPGaWwzPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import fiftyone.utils.coco as fouc\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class FiftyOneTorchDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\n",
        "    \n",
        "    Args:\n",
        "        fiftyone_dataset: a FiftyOne dataset or view that will be used for training or testing\n",
        "        transforms (None): a list of PyTorch transforms to apply to images and targets when loading\n",
        "        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset that contains the \n",
        "            desired labels to load\n",
        "        classes (None): a list of class strings that are used to define the mapping between\n",
        "            class names and indices. If None, it will use all classes present in the given fiftyone_dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        fiftyone_dataset,\n",
        "        transforms=None,\n",
        "        gt_field=\"ground_truth\",\n",
        "        classes=None,\n",
        "    ):\n",
        "        self.samples = fiftyone_dataset\n",
        "        self.transforms = transforms\n",
        "        self.gt_field = gt_field\n",
        "\n",
        "        self.img_paths = self.samples.values(\"filepath\")\n",
        "\n",
        "        self.classes = classes\n",
        "        if not self.classes:\n",
        "            # Get list of distinct labels that exist in the view\n",
        "            self.classes = self.samples.distinct(\n",
        "                \"%s.detections.label\" % gt_field\n",
        "            )\n",
        "\n",
        "        if self.classes[0] != \"background\":\n",
        "            self.classes = [\"background\"] + self.classes\n",
        "\n",
        "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        sample = self.samples[img_path]\n",
        "        metadata = sample.metadata\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        area = []\n",
        "        iscrowd = []\n",
        "        detections = sample[self.gt_field].detections\n",
        "        for det in detections:\n",
        "            category_id = self.labels_map_rev[det.label]\n",
        "            coco_obj = fouc.COCOObject.from_label(\n",
        "                det, metadata, category_id=category_id,\n",
        "            )\n",
        "            x, y, w, h = coco_obj.bbox\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(coco_obj.category_id)\n",
        "            area.append(coco_obj.area)\n",
        "            iscrowd.append(coco_obj.iscrowd)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target[\"image_id\"] = torch.as_tensor([idx])\n",
        "        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
        "        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def get_classes(self):\n",
        "        return self.classes"
      ],
      "metadata": {
        "id": "WG8vXMCEw-bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def get_model(num_classes):\n",
        "    # load a model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    \n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "yzkX50t8xFDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBadj5zKy-c-",
        "outputId": "b5f5be85-0d1e-4584-c640-351b49990260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 151610, done.\u001b[K\n",
            "remote: Counting objects: 100% (3986/3986), done.\u001b[K\n",
            "remote: Compressing objects: 100% (436/436), done.\u001b[K\n",
            "remote: Total 151610 (delta 3576), reused 3876 (delta 3535), pack-reused 147624\u001b[K\n",
            "Receiving objects: 100% (151610/151610), 295.81 MiB | 11.84 MiB/s, done.\n",
            "Resolving deltas: 100% (134147/134147), done.\n",
            "Note: checking out 'v0.3.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at be376084d version check against PyTorch's CUDA version\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import functions from the torchvision references we cloned\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "def do_training(model, torch_dataset, torch_dataset_test, num_epochs=4):\n",
        "    # define training and validation data loaders\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        torch_dataset, batch_size=2, shuffle=True, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "    \n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        torch_dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "    # train on the GPU or on the CPU, if a GPU is not available\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(\"Using device %s\" % device)\n",
        "\n",
        "    # move model to the right device\n",
        "    model.to(device)\n",
        "\n",
        "    # construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                                momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                    step_size=3,\n",
        "                                                    gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        evaluate(model, data_loader_test, device=device)"
      ],
      "metadata": {
        "id": "PnYc0EUvxIOc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}